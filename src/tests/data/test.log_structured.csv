LineId,Date,Time,Level,Component,Content,EventId,EventTemplate,ParameterList
1,20/02/28,22:47:36,INFO,JettyClient$,"Creating new HttpClient with SSLContextFactory=None,maxRequestHeaderSize=65536, namePrefix=Some(DBFSV1), idleTimeout=2 hours, useBlockingConnect: true",a8159908,"[ ' C r e a t i n g ' ,   ' n e w ' ,   ' H t t p C l i e n t ' ,   ' w i t h ' ,   ' S S L C o n t e x t F a c t o r y = N o n e , m a x R e q u e s t H e a d e r S i z e = 6 5 5 3 6 , ' ,   ' n a m e P r e f i x = S o m e ( D B F S V 1 ) , ' ,   ' i d l e T i m e o u t = 2 ' ,   ' h o u r s , ' ,   ' u s e B l o c k i n g C o n n e c t : ' ,   ' t r u e ' ]",[]
2,20/02/28,22:47:37,INFO,SharedState,Scheduler stats enabled.,3bb1372e,"[ ' S c h e d u l e r ' ,   ' s t a t s ' ,   ' e n a b l e d . ' ]",[]
3,20/02/28,22:47:37,INFO,SharedState,loading hive config file: file:/databricks/hive/conf/hive-site.xml,5ea78435,"[ ' l o a d i n g ' ,   ' h i v e ' ,   ' c o n f i g ' ,   ' f i l e : ' ,   ' f i l e : / d a t a b r i c k s / h i v e / c o n f / h i v e - s i t e . x m l ' ]",[]
4,20/02/28,22:47:37,INFO,SharedState,Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/user/hive/warehouse').,67f2600c,"[ ' S e t t i n g ' ,   ' h i v e . m e t a s t o r e . w a r e h o u s e . d i r ' ,   "" ( ' n u l l ' ) "" ,   ' t o ' ,   ' t h e ' ,   ' v a l u e ' ,   ' o f ' ,   ' s p a r k . s q l . w a r e h o u s e . d i r ' ,   "" ( ' / u s e r / h i v e / w a r e h o u s e ' ) . "" ]",[]
5,20/02/28,22:47:37,INFO,SharedState,Warehouse path is '/user/hive/warehouse'.,943ea220,"[ ' W a r e h o u s e ' ,   ' p a t h ' ,   ' i s ' ,   "" ' / u s e r / h i v e / w a r e h o u s e ' . "" ]",[]
6,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@5b066c33{/SQL,null,AVAILABLE,@Spark}",b6cbc761,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 5 b 0 6 6 c 3 3 { / S Q L , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
7,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@62ea8931{/SQL/json,null,AVAILABLE,@Spark}",83f6fc66,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 6 2 e a 8 9 3 1 { / S Q L / j s o n , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
8,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@71166348{/SQL/execution,null,AVAILABLE,@Spark}",2171019e,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 7 1 1 6 6 3 4 8 { / S Q L / e x e c u t i o n , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
9,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@6d874695{/SQL/execution/json,null,AVAILABLE,@Spark}",234a7ea8,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 6 d 8 7 4 6 9 5 { / S Q L / e x e c u t i o n / j s o n , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
10,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@10ed037a{/static/sql,null,AVAILABLE,@Spark}",3d3614ba,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 1 0 e d 0 3 7 a { / s t a t i c / s q l , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
11,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@150fc7a7{/storage/iocache,null,AVAILABLE,@Spark}",b16fc8e5,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 1 5 0 f c 7 a 7 { / s t o r a g e / i o c a c h e , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
12,20/02/28,22:47:37,INFO,ContextHandler,"Started o.e.j.s.ServletContextHandler@55d8c2c4{/storage/iocache/json,null,AVAILABLE,@Spark}",9bac1f1b,"[ ' S t a r t e d ' ,   ' o . e . j . s . S e r v l e t C o n t e x t H a n d l e r @ 5 5 d 8 c 2 c 4 { / s t o r a g e / i o c a c h e / j s o n , n u l l , A V A I L A B L E , @ S p a r k } ' ]",[]
13,20/02/28,22:47:37,INFO,DatabricksILoop$,Finished creating throwaway interpreter,ec4b9c55,"[ ' F i n i s h e d ' ,   ' c r e a t i n g ' ,   ' t h r o w a w a y ' ,   ' i n t e r p r e t e r ' ]",[]
14,20/02/28,22:47:38,INFO,StateStoreCoordinatorRef,Registered StateStoreCoordinator endpoint,4f181175,"[ ' R e g i s t e r e d ' ,   ' S t a t e S t o r e C o o r d i n a t o r ' ,   ' e n d p o i n t ' ]",[]
15,20/02/28,22:47:40,INFO,HiveUtils,"Initializing execution hive, version 1.2.1",8e62b1eb,"[ ' I n i t i a l i z i n g ' ,   ' e x e c u t i o n ' ,   ' h i v e , ' ,   ' v e r s i o n ' ,   ' 1 . 2 . 1 ' ]",[]
16,20/02/28,22:47:41,INFO,HiveMetaStore,0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore,7e5e28e2,"[ ' 0 : ' ,   ' O p e n i n g ' ,   ' r a w ' ,   ' s t o r e ' ,   ' w i t h ' ,   ' i m p l e m e n a t i o n ' ,   ' c l a s s : o r g . a p a c h e . h a d o o p . h i v e . m e t a s t o r e . O b j e c t S t o r e ' ]",[]
17,20/02/28,22:47:41,INFO,ObjectStore,"ObjectStore, initialize called",6d1bf8fd,"[ ' O b j e c t S t o r e , ' ,   ' i n i t i a l i z e ' ,   ' c a l l e d ' ]",[]
18,20/02/28,22:47:41,INFO,Persistence,Property hive.metastore.integral.jdo.pushdown unknown - will be ignored,f1688e60,"[ ' P r o p e r t y ' ,   ' h i v e . m e t a s t o r e . i n t e g r a l . j d o . p u s h d o w n ' ,   ' u n k n o w n ' ,   ' - ' ,   ' w i l l ' ,   ' b e ' ,   ' i g n o r e d ' ]",[]
19,20/02/28,22:47:41,INFO,Persistence,Property datanucleus.cache.level2 unknown - will be ignored,d4e3f26d,"[ ' P r o p e r t y ' ,   ' d a t a n u c l e u s . c a c h e . l e v e l 2 ' ,   ' u n k n o w n ' ,   ' - ' ,   ' w i l l ' ,   ' b e ' ,   ' i g n o r e d ' ]",[]
20,20/02/28,22:47:41,INFO,Persistence,Property datanucleus.schema.autoCreateAll unknown - will be ignored,2bad136b,"[ ' P r o p e r t y ' ,   ' d a t a n u c l e u s . s c h e m a . a u t o C r e a t e A l l ' ,   ' u n k n o w n ' ,   ' - ' ,   ' w i l l ' ,   ' b e ' ,   ' i g n o r e d ' ]",[]
21,20/02/28,22:47:44,INFO,ObjectStore,"Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=""Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order""",12c97590,"[ ' S e t t i n g ' ,   ' M e t a S t o r e ' ,   ' o b j e c t ' ,   ' p i n ' ,   ' c l a s s e s ' ,   ' w i t h ' ,   ' h i v e . m e t a s t o r e . c a c h e . p i n o b j t y p e s = "" T a b l e , S t o r a g e D e s c r i p t o r , S e r D e I n f o , P a r t i t i o n , D a t a b a s e , T y p e , F i e l d S c h e m a , O r d e r "" ' ]",[]
22,20/02/28,22:47:46,INFO,Datastore,"The class ""org.apache.hadoop.hive.metastore.model.MFieldSchema"" is tagged as ""embedded-only"" so does not have its own datastore table.",38bb10f7,"[ ' T h e ' ,   ' c l a s s ' ,   ' "" o r g . a p a c h e . h a d o o p . h i v e . m e t a s t o r e . m o d e l . M F i e l d S c h e m a "" ' ,   ' i s ' ,   ' t a g g e d ' ,   ' a s ' ,   ' "" e m b e d d e d - o n l y "" ' ,   ' s o ' ,   ' d o e s ' ,   ' n o t ' ,   ' h a v e ' ,   ' i t s ' ,   ' o w n ' ,   ' d a t a s t o r e ' ,   ' t a b l e . ' ]",[]
23,20/02/28,22:47:46,INFO,Datastore,"The class ""org.apache.hadoop.hive.metastore.model.MOrder"" is tagged as ""embedded-only"" so does not have its own datastore table.",fd23f351,"[ ' T h e ' ,   ' c l a s s ' ,   ' "" o r g . a p a c h e . h a d o o p . h i v e . m e t a s t o r e . m o d e l . M O r d e r "" ' ,   ' i s ' ,   ' t a g g e d ' ,   ' a s ' ,   ' "" e m b e d d e d - o n l y "" ' ,   ' s o ' ,   ' d o e s ' ,   ' n o t ' ,   ' h a v e ' ,   ' i t s ' ,   ' o w n ' ,   ' d a t a s t o r e ' ,   ' t a b l e . ' ]",[]
24,20/02/28,22:47:47,INFO,Datastore,"The class ""org.apache.hadoop.hive.metastore.model.MFieldSchema"" is tagged as ""embedded-only"" so does not have its own datastore table.",38bb10f7,"[ ' T h e ' ,   ' c l a s s ' ,   ' "" o r g . a p a c h e . h a d o o p . h i v e . m e t a s t o r e . m o d e l . M F i e l d S c h e m a "" ' ,   ' i s ' ,   ' t a g g e d ' ,   ' a s ' ,   ' "" e m b e d d e d - o n l y "" ' ,   ' s o ' ,   ' d o e s ' ,   ' n o t ' ,   ' h a v e ' ,   ' i t s ' ,   ' o w n ' ,   ' d a t a s t o r e ' ,   ' t a b l e . ' ]",[]
25,20/02/28,22:47:47,INFO,Datastore,"The class ""org.apache.hadoop.hive.metastore.model.MOrder"" is tagged as ""embedded-only"" so does not have its own datastore table.",fd23f351,"[ ' T h e ' ,   ' c l a s s ' ,   ' "" o r g . a p a c h e . h a d o o p . h i v e . m e t a s t o r e . m o d e l . M O r d e r "" ' ,   ' i s ' ,   ' t a g g e d ' ,   ' a s ' ,   ' "" e m b e d d e d - o n l y "" ' ,   ' s o ' ,   ' d o e s ' ,   ' n o t ' ,   ' h a v e ' ,   ' i t s ' ,   ' o w n ' ,   ' d a t a s t o r e ' ,   ' t a b l e . ' ]",[]
26,20/02/28,22:47:47,INFO,MetaStoreDirectSql,"Using direct SQL, underlying DB is DERBY",62fc0dc9,"[ ' U s i n g ' ,   ' d i r e c t ' ,   ' S Q L , ' ,   ' u n d e r l y i n g ' ,   ' D B ' ,   ' i s ' ,   ' D E R B Y ' ]",[]
27,20/02/28,22:47:47,INFO,ObjectStore,Initialized ObjectStore,a861e1ab,"[ ' I n i t i a l i z e d ' ,   ' O b j e c t S t o r e ' ]",[]
28,20/02/28,22:47:47,WARN,ObjectStore,Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0,35dbeafa,"[ ' V e r s i o n ' ,   ' i n f o r m a t i o n ' ,   ' n o t ' ,   ' f o u n d ' ,   ' i n ' ,   ' m e t a s t o r e . ' ,   ' h i v e . m e t a s t o r e . s c h e m a . v e r i f i c a t i o n ' ,   ' i s ' ,   ' n o t ' ,   ' e n a b l e d ' ,   ' s o ' ,   ' r e c o r d i n g ' ,   ' t h e ' ,   ' s c h e m a ' ,   ' v e r s i o n ' ,   ' 1 . 2 . 0 ' ]",[]
29,20/02/28,22:47:48,WARN,ObjectStore,"Failed to get database default, returning NoSuchObjectException",c321a950,"[ ' F a i l e d ' ,   ' t o ' ,   ' g e t ' ,   ' d a t a b a s e ' ,   ' d e f a u l t , ' ,   ' r e t u r n i n g ' ,   ' N o S u c h O b j e c t E x c e p t i o n ' ]",[]
30,20/02/28,22:47:48,INFO,HiveMetaStore,Added admin role in metastore,011c3f85,"[ ' A d d e d ' ,   ' a d m i n ' ,   ' r o l e ' ,   ' i n ' ,   ' m e t a s t o r e ' ]",[]
31,20/02/28,22:47:48,INFO,HiveMetaStore,Added public role in metastore,703c6d4f,"[ ' A d d e d ' ,   ' p u b l i c ' ,   ' r o l e ' ,   ' i n ' ,   ' m e t a s t o r e ' ]",[]
32,20/02/28,22:47:48,INFO,HiveMetaStore,"No user is added in admin role, since config is empty",998b28e4,"[ ' N o ' ,   ' u s e r ' ,   ' i s ' ,   ' a d d e d ' ,   ' i n ' ,   ' a d m i n ' ,   ' r o l e , ' ,   ' s i n c e ' ,   ' c o n f i g ' ,   ' i s ' ,   ' e m p t y ' ]",[]
33,20/02/28,22:47:48,INFO,HiveMetaStore,0: get_all_databases,52d4d655,"[ ' 0 : ' ,   ' g e t _ a l l _ d a t a b a s e s ' ]",[]
34,20/02/28,22:47:48,INFO,audit,ugi=root	ip=unknown-ip-addr	cmd=get_all_databases,4bc8fdfb,"[ ' u g i = r o o t ' ,   ' i p = u n k n o w n - i p - a d d r ' ,   ' c m d = g e t _ a l l _ d a t a b a s e s ' ]",[]
35,20/02/28,22:47:48,INFO,HiveMetaStore,0: get_functions: db=default pat=*,f9ebe1a6,"[ ' 0 : ' ,   ' g e t _ f u n c t i o n s : ' ,   ' d b = d e f a u l t ' ,   ' p a t = * ' ]",[]
36,20/02/28,22:47:48,INFO,audit,ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*,5258c633,"[ ' u g i = r o o t ' ,   ' i p = u n k n o w n - i p - a d d r ' ,   ' c m d = g e t _ f u n c t i o n s : ' ,   ' d b = d e f a u l t ' ,   ' p a t = * ' ]",[]
